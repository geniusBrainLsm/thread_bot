# MCP Bot Execution Flow Documentation

## Overview
This document provides detailed execution flows for all major operations in the Multi-Topic MCP (Meta Content Poster) bot system.

## Table of Contents
1. [Application Startup Flow](#application-startup-flow)
2. [Scheduled Pipeline Flows](#scheduled-pipeline-flows)
3. [Content Generation Flow](#content-generation-flow)
4. [News Crawling Flow](#news-crawling-flow)
5. [Posting Flow](#posting-flow)
6. [API Request Flows](#api-request-flows)
7. [Error Handling Flows](#error-handling-flows)

---

## Application Startup Flow

### 1. Spring Boot Application Initialization
```
IdeaPrintApplication.main()
  â†“
Spring Context Initialization
  â†“
@Order(1) TopicDataInitializer.run()
  â†“ 
@Order(2) NewsSourceDataInitializer.run()
  â†“
WebClient Configuration
  â†“
Scheduling Service Activation
  â†“
API Controllers Ready
```

### 2. TopicDataInitializer Execution Flow
```java
TopicDataInitializer.run()
  â†“
initializeDefaultTopics()
  â”œâ”€ Check if "ai" topic exists
  â”‚  â””â”€ Create AI ContentTopic with default prompt
  â”œâ”€ Check if "life-hacks" topic exists  
  â”‚  â””â”€ Create Life-Hacks ContentTopic (inactive)
  â””â”€ Check if "general" topic exists
     â””â”€ Create General ContentTopic
  â†“
updateNewsSourcesWithTopics()
  â””â”€ Assign AI topic to existing AI-related sources
```

### 3. NewsSourceDataInitializer Execution Flow
```java
NewsSourceDataInitializer.run()
  â†“
initializeDefaultNewsSources()
  â”œâ”€ Get AI topic from database
  â”œâ”€ Create "the-neuron-daily" source â†’ Link to AI topic
  â”œâ”€ Create "ai-news" source â†’ Link to AI topic  
  â””â”€ Create "venturebeat-ai" source â†’ Link to AI topic
```

---

## Scheduled Pipeline Flows

### 1. Multi-Topic Pipeline (10:30 AM)
```java
@Scheduled(cron = "0 30 10 * * *")
ScheduleService.executeMultiTopicPipeline()
  â†“
MultiTopicMcpService.executeFullPipelineForAllTopics()
  â†“
ContentTopicRepository.findByIsActiveTrue()
  â†“
For each active topic:
  â””â”€ MultiTopicMcpService.executeTopicPipeline(topicName)
     â”œâ”€ TopicBasedCrawlerService.crawlLatestNewsForTopic(topicName)
     â”‚  â”œâ”€ NewsSourceRepository.findByContentTopicNameAndIsActiveTrue(topicName)
     â”‚  â”œâ”€ For each source: crawlFromSource(source)
     â”‚  â”‚  â”œâ”€ Jsoup.connect(source.baseUrl)
     â”‚  â”‚  â”œâ”€ Extract title, URL, summary using selectors
     â”‚  â”‚  â””â”€ ValidationUtils.isValidNewsArticle(article)
     â”‚  â””â”€ Return first valid article found
     â”œâ”€ DuplicatePreventionService.isArticleAlreadyPosted(article)
     â”‚  â””â”€ RedisTemplate.hasKey(article.generateRedisKey())
     â”œâ”€ TopicBasedPostingService.postArticleToTopicAccounts(article, topicName)
     â”‚  â”œâ”€ MetaTokenRepository.findByContentTopicName(topicName)
     â”‚  â””â”€ For each account in topic:
     â”‚     â”œâ”€ TopicBasedContentGenerationService.generatePersonalizedContentForAccount(article, account)
     â”‚     â”‚  â”œâ”€ Determine prompt (account â†’ topic â†’ default)
     â”‚     â”‚  â”œâ”€ AccountPromptService.formatPromptWithArticle()
     â”‚     â”‚  â””â”€ Gpt4Service.generatePost(prompt)
     â”‚     â”œâ”€ ThreadsPostService.doPost(content, userId, accessToken)
     â”‚     â”‚  â”œâ”€ Create Threads post container
     â”‚     â”‚  â””â”€ Publish Threads post
     â”‚     â””â”€ MetaToken.incrementPostCount() + save
     â”œâ”€ DuplicatePreventionService.markArticleAsPosted(article)
     â”‚  â””â”€ RedisTemplate.opsForValue().set(key, title, 24hours)
     â””â”€ NotificationService.notifySuccess/notifyFailure()
        â””â”€ SlackNotificationService.sendSlackMessage()
```

### 2. Cross-Topic Pipeline (2:00 PM)
```java
@Scheduled(cron = "0 0 14 * * *")
ScheduleService.executeCrossTopicPipeline()
  â†“
MultiTopicMcpService.executeCrossTopicPipeline()
  â†“
TopicBasedCrawlerService.crawlAllTopics()
  â”œâ”€ ContentTopicRepository.findByIsActiveTrue()
  â””â”€ For each topic:
     â”œâ”€ TopicBasedCrawlerService.crawlAllSourcesForTopic(topicName)
     â”‚  â”œâ”€ NewsSourceRepository.findByContentTopicNameAndIsActiveTrue(topicName)
     â”‚  â””â”€ For each source: crawlFromSourceSafe(source)
     â””â”€ Collect all articles by topic
  â†“
For each topic's articles:
  â”œâ”€ DuplicatePreventionService.isArticleAlreadyPosted(article)
  â”œâ”€ TopicBasedPostingService.postArticleToTopicAccounts(article, topicName)
  â”‚  â””â”€ [Same posting flow as Multi-Topic Pipeline]
  â””â”€ DuplicatePreventionService.markArticleAsPosted(article)
```

### 3. Universal Pipeline (4:00 PM)
```java
@Scheduled(cron = "0 0 16 * * *")
ScheduleService.executeUniversalPipeline()
  â†“
MultiTopicMcpService.executeUniversalPipeline()
  â†“
TopicBasedCrawlerService.crawlLatestNewsForTopic("ai")
  â””â”€ [Same crawling flow as topic-specific]
  â†“
DuplicatePreventionService.isArticleAlreadyPosted(article)
  â†“
TopicBasedPostingService.postArticleToAllTopicAccounts(article)
  â”œâ”€ MetaTokenRepository.findByActiveContentTopic()
  â””â”€ For each account across all topics:
     â”œâ”€ TopicBasedContentGenerationService.generatePersonalizedContentForAccount(article, account)
     â”‚  â”œâ”€ Account prompt takes priority
     â”‚  â”œâ”€ Fall back to account's topic default prompt
     â”‚  â””â”€ Generate content with account's topic context
     â”œâ”€ ThreadsPostService.doPost(personalizedContent, userId, accessToken)
     â””â”€ MetaToken.incrementPostCount() + save
```

### 4. AI Topic Pipeline (11:00 AM)
```java
@Scheduled(cron = "0 0 11 * * *")
ScheduleService.executeAiTopicPipeline()
  â†“
MultiTopicMcpService.executeTopicPipeline("ai")
  â””â”€ [Same flow as single topic in Multi-Topic Pipeline]
```

### 5. Legacy Pipeline (9:00 AM)
```java
@Scheduled(cron = "0 0 9 * * *")
ScheduleService.executeMcpPipeline()
  â†“
McpService.executeFullPipeline()
  â”œâ”€ MultiSiteNewsCrawlerService.crawlLatestAiNews()
  â”œâ”€ DuplicatePreventionService.isArticleAlreadyPosted(article)
  â”œâ”€ ThreadsPostService.postArticleToAllAccounts(article)
  â”‚  â””â”€ Uses McpContentGenerationService for account-specific content
  â””â”€ DuplicatePreventionService.markArticleAsPosted(article)
```

---

## Content Generation Flow

### 1. Personalized Content Generation
```java
TopicBasedContentGenerationService.generatePersonalizedContentForAccount(article, account)
  â†“
determinePromptForAccount(account, article)
  â”œâ”€ Check account.getPrompt() (highest priority)
  â”œâ”€ Check account.getContentTopic().getDefaultPrompt()
  â”œâ”€ Check getDefaultPromptForSource(article.getSourceName())
  â””â”€ Fall back to getDefaultPromptForTopic("general")
  â†“
AccountPromptService.formatPromptWithArticle(prompt, title, summary, url, sourceName)
  â””â”€ String.format(prompt, title, summary, url, sourceName)
  â†“
Gpt4Service.generatePost(contextualPrompt)
  â”œâ”€ WebClient.post() to OpenAI API
  â”‚  â”œâ”€ Model: "gpt-4.1"
  â”‚  â”œâ”€ Messages: [{"role": "user", "content": prompt}]
  â”‚  â””â”€ Store: true
  â”œâ”€ Extract response content
  â””â”€ Return generated text
  â†“
Content validation and fallback handling
  â”œâ”€ Check if content is not null/empty
  â”œâ”€ Filter and validate content
  â””â”€ Return generateFallbackContent(article) if needed
```

### 2. Topic-Specific Prompt Selection
```java
getDefaultPromptForTopic(topicName)
  â†“
Switch on topicName.toLowerCase():
  â”œâ”€ "ai" â†’ AI-focused prompt template
  â”‚  â”œâ”€ Tech-savvy tone
  â”‚  â”œâ”€ AI emojis (ğŸ§ , ğŸ¤–, âš¡, ğŸš€)
  â”‚  â””â”€ Hashtags (#AI #MachineLearning #Tech #Innovation)
  â”œâ”€ "life-hacks" â†’ Productivity-focused prompt template
  â”‚  â”œâ”€ Friendly, helpful tone
  â”‚  â”œâ”€ Productivity emojis (ğŸ’¡, âš¡, ğŸ¯, ğŸ”¥)
  â”‚  â””â”€ Hashtags (#LifeHacks #Productivity #Tips #LifeStyle)
  â””â”€ default â†’ General prompt template
     â”œâ”€ Casual, engaging tone
     â”œâ”€ Generic emojis
     â””â”€ Basic hashtags
```

### 3. Fallback Content Generation
```java
generateFallbackContent(article)
  â†“
Format basic template:
  "ğŸ¤– {title}\n\n{summary}\n\n#Content #Update\n\n{url}"
  â†“
Length validation:
  â”œâ”€ If title > 100 chars â†’ truncate to 97 + "..."
  â”œâ”€ If summary > 120 chars â†’ truncate to 117 + "..."
  â””â”€ If total > 500 chars â†’ use shortened format
```

---

## News Crawling Flow

### 1. Topic-Based Crawling
```java
TopicBasedCrawlerService.crawlLatestNewsForTopic(topicName)
  â†“
NewsSourceRepository.findByContentTopicNameAndIsActiveTrue(topicName)
  â†“
For each source in topic:
  â””â”€ crawlFromSource(source)
     â”œâ”€ Jsoup.connect(source.getBaseUrl())
     â”‚  â”œâ”€ Timeout: source.getTimeoutMs()
     â”‚  â”œâ”€ UserAgent: source.getUserAgent()
     â”‚  â””â”€ Get Document
     â”œâ”€ Extract first article using source.getArticleSelector()
     â”œâ”€ extractTitle(firstArticle, doc, source)
     â”‚  â”œâ”€ Try source.getTitleSelector()
     â”‚  â””â”€ Fall back to "h1, title"
     â”œâ”€ extractUrl(firstArticle, source)
     â”‚  â”œâ”€ Try source.getUrlSelector()
     â”‚  â”œâ”€ Handle relative URLs (prepend baseUrl)
     â”‚  â””â”€ Return absolute URL
     â”œâ”€ extractSummary(firstArticle, source)
     â”‚  â”œâ”€ Try source.getSummarySelector()
     â”‚  â””â”€ Truncate if > 300 chars
     â”œâ”€ Create NewsArticle with source attribution
     â”œâ”€ ValidationUtils.isValidNewsArticle(article)
     â”‚  â”œâ”€ Check title not empty
     â”‚  â”œâ”€ Check URL format
     â”‚  â””â”€ Validate content structure
     â””â”€ Return Optional<NewsArticle>
```

### 2. Multi-Source Crawling
```java
TopicBasedCrawlerService.crawlAllSourcesForTopic(topicName)
  â†“
NewsSourceRepository.findByContentTopicNameAndIsActiveTrue(topicName)
  â†“
sources.stream()
  .map(this::crawlFromSourceSafe)
  .filter(Optional::isPresent)
  .map(Optional::get)
  .peek(article â†’ article.setSourceName(topicName + ":" + article.getSourceName()))
  .toList()
```

### 3. All-Topics Crawling
```java
TopicBasedCrawlerService.crawlAllTopics()
  â†“
ContentTopicRepository.findByIsActiveTrue()
  â†“
For each active topic:
  â”œâ”€ crawlAllSourcesForTopic(topic.getName())
  â”œâ”€ Collect articles into Map<String, List<NewsArticle>>
  â””â”€ Log article count per topic
```

---

## Posting Flow

### 1. Account-Specific Posting
```java
TopicBasedPostingService.postArticleToTopicAccounts(article, topicName)
  â†“
MetaTokenRepository.findByContentTopicName(topicName)
  â†“
Flux.fromIterable(topicAccounts)
  .flatMap(account â†’ {
    // Generate personalized content
    TopicBasedContentGenerationService.generatePersonalizedContentForAccount(article, account)
    â†“
    ThreadsPostService.doPost(personalizedContent, account.getUserId(), account.getAccessToken())
      â”œâ”€ Create Threads post container
      â”‚  â”œâ”€ POST /{userId}/threads
      â”‚  â”œâ”€ Body: {"media_type": "TEXT", "text": content}
      â”‚  â””â”€ Query: access_token
      â”œâ”€ Get creation_id from response
      â””â”€ Publish Threads post
         â”œâ”€ POST /{userId}/threads_publish
         â”œâ”€ Body: {"creation_id": creationId}
         â””â”€ Return published post response
    â†“
    // Update account statistics
    account.incrementPostCount()
    metaTokenRepository.save(account)
    â†“
    return success/failure status
  })
  .collectList()
  .block()
```

### 2. Cross-Topic Posting
```java
TopicBasedPostingService.postArticleToAllTopicAccounts(article)
  â†“
MetaTokenRepository.findByActiveContentTopic()
  â†“
For each account across all active topics:
  â”œâ”€ TopicBasedContentGenerationService.generatePersonalizedContentForAccount(article, account)
  â”‚  â””â”€ Uses account's topic context for personalization
  â”œâ”€ ThreadsPostService.doPost(personalizedContent, userId, accessToken)
  â””â”€ account.incrementPostCount() + save
```

### 3. Topic-Separated Posting
```java
TopicBasedPostingService.postArticleToAllTopicsSeparately(article)
  â†“
ContentTopicRepository.findByIsActiveTrue()
  â†“
topics.stream().collect(Collectors.toMap(
  ContentTopic::getName,
  topic â†’ postArticleToTopicAccounts(article, topic.getName())
))
  â†“
Returns Map<String, Boolean> of topic success status
```

---

## API Request Flows

### 1. Topic Management API
```java
POST /api/content-topics
ContentTopicController.createTopic(topic)
  â†“
ContentTopicRepository.save(topic)
  â†“
ApiResponse.success("í† í”½ ìƒì„± ì„±ê³µ", savedTopic)
```

```java
GET /api/content-topics/stats
ContentTopicController.getTopicAccountStats()
  â†“
MultiTopicMcpService.getTopicAccountStats()
  â†“
TopicBasedPostingService.getAccountCountByTopic()
  â”œâ”€ ContentTopicRepository.findByIsActiveTrue()
  â””â”€ For each topic: MetaTokenRepository.findByContentTopic(topic).size()
```

### 2. Account-Topic Assignment API
```java
PUT /api/account-prompts/{userId}/topic
AccountPromptController.assignTopicToAccount(userId, request)
  â†“
MetaTokenRepository.findByUserId(userId)
  â†“
ContentTopicRepository.findByName(topicName)
  â†“
account.setContentTopic(topic)
  â†“
MetaTokenRepository.save(account)
  â†“
ApiResponse.success("ê³„ì • í† í”½ í• ë‹¹ ì„±ê³µ", updatedAccount)
```

### 3. Pipeline Execution API
```java
POST /api/content-topics/{topicName}/execute
ContentTopicController.executeTopicPipeline(topicName)
  â†“
MultiTopicMcpService.executeTopicPipeline(topicName)
  â””â”€ [Same flow as scheduled topic pipeline]
  â†“
Return ApiResponse with success/failure status
```

---

## Error Handling Flows

### 1. Exception Hierarchy Flow
```
Exception occurs in any service
  â†“
Check exception type:
  â”œâ”€ CrawlingException
  â”‚  â”œâ”€ Log crawling error
  â”‚  â”œâ”€ NotificationService.notifyFailure("Crawling Error", message)
  â”‚  â””â”€ Continue with next source/topic
  â”œâ”€ ContentGenerationException
  â”‚  â”œâ”€ Log generation error  
  â”‚  â”œâ”€ NotificationService.notifyFailure("Content Generation Error", message)
  â”‚  â””â”€ Use fallback content generation
  â”œâ”€ PostingException
  â”‚  â”œâ”€ Log posting error
  â”‚  â”œâ”€ NotificationService.notifyFailure("Posting Error", message)
  â”‚  â””â”€ Continue with next account
  â””â”€ General Exception
     â”œâ”€ Log general error with context
     â”œâ”€ NotificationService.notifyFailure("Pipeline Error", message)
     â””â”€ Stop current operation
```

### 2. Reactive Error Handling
```java
Gpt4Service.generatePost(prompt)
  .filter(content â†’ content != null && !content.trim().isEmpty())
  .doOnNext(content â†’ log.info("Successfully generated content"))
  .doOnError(error â†’ log.error("Failed to generate content", error))
  .onErrorReturn(generateFallbackContent(article))
  .map(String::trim)
```

### 3. Validation Error Flow
```java
ValidationUtils.isValidNewsArticle(article)
  â”œâ”€ Check article != null
  â”œâ”€ Check title not empty
  â”œâ”€ Check URL not empty
  â”œâ”€ Check URL format (http/https)
  â””â”€ Return boolean validation result
  â†“
If validation fails:
  â”œâ”€ Log validation warning
  â”œâ”€ Return Optional.empty()
  â””â”€ Continue with next source
```

### 4. Notification Flow
```java
NotificationService.notifyFailure(title, message)
  â†“
SlackNotificationService.notifyFailure(title, message)
  â†“
Check if slackWebhookUrl is configured
  â”œâ”€ If not configured: log warning and return
  â””â”€ If configured: sendSlackMessage(formattedMessage)
     â”œâ”€ WebClient.post().uri(slackWebhookUrl)
     â”œâ”€ Body: {"text": message}
     â””â”€ Fire-and-forget with error logging
```

---

## Performance Considerations

### 1. Reactive Streams
- Non-blocking I/O for external API calls
- Parallel processing of multiple accounts
- Backpressure handling for large account lists

### 2. Database Optimization
- Indexed queries on topic relationships
- Batch operations for account updates
- Connection pooling for concurrent access

### 3. Caching Strategy
- Redis for duplicate prevention (24-hour TTL)
- Potential content caching for repeated articles
- Topic/account mapping caching

### 4. Rate Limiting
- Configurable timeouts for news source crawling
- Built-in delays between API calls
- Circuit breaker pattern for external services

This execution flow documentation provides a comprehensive view of how the Multi-Topic MCP bot operates, from startup initialization through complex multi-topic content distribution workflows.